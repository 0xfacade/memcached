Storage system notes
--------------------

extstore.h defines the API.

extstore_write() is a synchronous call which memcpy's the input buffer into a
write buffer for an active page. A failure is not usually a hard failure, but
indicates caller can try again another time. IE: it might be busy freeing
pages or assigning new ones.

as of this writing the write() implementation doesn't have an internal loop,
so it can give spurious failures (good for testing integration)

extstore_read() is an asynchronous call which takes a stack of IO objects and
adds it to the end of a queue. It then signals the IO thread to run. Once an
IO stack is submitted the caller must not touch the submitted objects anymore
(they are relinked internally).

The IO threads execute each object in turn (or in bulk of running in the
future libaio mode).

Callbacks are issued from the IO threads. It's thus important to keep
processing to a minimum. Callbacks may be issued out of order, and it is the
caller's responsibility to know when its stack has been fully processed so it
may reclaim the memory.

With DIRECT_IO support, buffers submitted for read/write will need to be
aligned with posix_memalign() or similar.

Memcached integration
---------------------

With the POC: items.c's lru_maintainer_thread calls writes to storage if all
memory has been allocated out to slab classes, and there is less than an
amount of memory free. Original objects are swapped with items marked with
ITEM_HDR flag. an ITEM_HDR contains copies of the original key and most of the
header data. The ITEM_data() section of an ITEM_HDR object contains (item_hdr
*), which describes enough information to retrieve the original object from
storage.

To get best performance is important that reads can be deeply pipelined.
As much processing as possible is done ahead of time, IO's are submitted, and
once IO's are done processing a minimal amount of code is executed before
transmit() is possible. This should amortize the amount of latency incurred by
hopping threads and waiting on IO.

Compaction etc
--------------

Storage pages contain CAS values which are not presently implemented. At some
point during a fetch the CAS value from the ITEM_HDR object needs to be
compared to the current existing page, and a read will fail if the page has
been wiped since the header object was created.

Pages will be reaped by an estimate of how few real objects it still contains.

[TBD]

TODO
----

Sharing my broad TODO items into here. While doing the work they get split up
more into local notes. Adding this so others can follow along:

- extstore_delete() function to decrement object count for a page
- figure out page refcounting
  - determine if this is necessary. If each IO is checked late stage, pages
    could be refcounted just before/after the IO rather than during IO's being
    queued. Lots of locking, so atomics might actually be okay here.
- page CAS/version validation during read.
  - return a miss into the callback from IO thread? Probably, because anything
    else would be a race condition so better to have one code path.
- pages readying to be reaped mark as "deprecated".
  - add function a crawler could use to tell if an item's page is going to be reaped
    "soon" (thus chuck back into memory)
  - *maybe* a callback that hands sections or the entirety of a page about to
    be nuked.
  - want to keep this simple; objects are not individually tracked, so a page
    reclaim simple wipes the storage out from under headers.
    - however, if very compact representation of objects -> offset/len/TTL
      could be kept in memory (possibly just for "low TTL" pages), one could
      callback for each tracked object that it thinks are still valid. Since
      the written object should be a mirror (or close to) the original memory
      object, a normal lookup could be done and the data swapped back into
      cache or written back to a new page.
    - at 4b per off/len/ttl against 1k objects in a 64 meg page, that's .8m of
      memory per 64m of flash? not great. If DIRECT_IO is in use could cut to
      2b for off/len easy (multiples of sectors)
    - ^^^ being able to recover valid items from an aged out page is a
      second-pass goal.
- maintenance thread sorts page list and assigns pages to low or high TTL
  active buckets.
- sort write buffers properly (collapse IO code; enforce 2 buffers per active
  page)
- TTL histogram aging for maintenance thread
- DIRECT_IO support
- libaio support (requires DIRECT_IO)
- TRIM support
- some stats counters that can be polled
  - page turnover, writes, reads, trims, etc.
- JBOD support (also not first pass)
  - 1-2 active pages per device. potentially dedicated IO threads per device.
    with a RAID setup you risk any individual disk doing a GC pause stalling
    all writes. with many disks these stalls can become constant.

on memcached end:
- shunt to flash if tail of COLD has age > N or if free memory is below X
  - and remaining TTL is > Y
- re-raise from flash into WARM if hit more than once in N seconds (60?), with
  a percentage chance (ex: objects getting hit multiple times within 60
  seconds get a 20% chance of pulling back into WARM, deleting from flash)
  - better if the percentage or age could dynamically raise by the amount of
    idle time the IO threads have.
  - not a first pass task
  - requires item CAS be enabled (compared CAS for ITEM_HDR object with what
    was on flash)
- complete code paths for miss
- fix append/prepend/incr/decr/etc
- proper counters/documentation (flash hit/miss rate)
- proper startup options
- --configure gating for extstore being compiled (for now, at least)
- binprot support
- crc32 checking (hardware/non hardware). embed in object header, or overwrite
  some non-essential bytes of original object before sending to flash
- DIRECT_IO support; mostly memalign pages, but also making chunks grow
  aligned to sector sizes once they are >= a single sector.
